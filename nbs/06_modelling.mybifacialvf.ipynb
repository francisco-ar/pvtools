{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp modelling.mybifacialvf\n",
    "#default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from capetools.imports import *\n",
    "from capetools.utils.tmy import read_tmy\n",
    "import bifacialvf\n",
    "import pvlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bifacialvf\n",
    "> A wrapper around NREL's bifacialvf, you need my version of [bifacialvf](http://github.com/tcapelle/bifacialvf). \n",
    "\n",
    "PLease install using \n",
    "```\n",
    "pip install git+https://github.com/tcapelle/bifacialvf\n",
    "``` \n",
    "before using this notebook.\n",
    "It ads various very necessary functionalities to bifacialvf:\n",
    "    - Uses pandas `DataFrames`'s as input data, through the use of `smimulate_inner` function\n",
    "    - Uses timestamps on files, instead of the Year, Month, Day... splited dates\n",
    "    - It is faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put some gps data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "CHAMBERY = {'Name':'Chambery', 'Latitude': 45.637001, 'Longitude': 5.881, 'Elevation': 235.0, 'TZ':-1.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bifacialvf has hard-coded column names 🤣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/tc256760/Documents/capetools/data/pvgis_tmy_chambery.csv'),Path('/home/tc256760/Documents/capetools/data/sample_data.hdf')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATAPATH = Path.cwd().parent/'data'\n",
    "DATAPATH.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ghi</th>\n",
       "      <th>dni</th>\n",
       "      <th>dhi</th>\n",
       "      <th>temp_air</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>pressure</th>\n",
       "      <th>humidity</th>\n",
       "      <th>zenith</th>\n",
       "      <th>elevation</th>\n",
       "      <th>azimuth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date UTC</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>4.39</td>\n",
       "      <td>1.87</td>\n",
       "      <td>230.1</td>\n",
       "      <td>1004.92</td>\n",
       "      <td>86.8</td>\n",
       "      <td>157.029</td>\n",
       "      <td>-67.029</td>\n",
       "      <td>12.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>-0.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>4.33</td>\n",
       "      <td>2.87</td>\n",
       "      <td>228.9</td>\n",
       "      <td>1004.94</td>\n",
       "      <td>86.8</td>\n",
       "      <td>152.143</td>\n",
       "      <td>-62.143</td>\n",
       "      <td>42.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>4.29</td>\n",
       "      <td>2.86</td>\n",
       "      <td>229.4</td>\n",
       "      <td>1004.68</td>\n",
       "      <td>86.7</td>\n",
       "      <td>143.742</td>\n",
       "      <td>-53.742</td>\n",
       "      <td>63.390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>4.15</td>\n",
       "      <td>2.04</td>\n",
       "      <td>186.0</td>\n",
       "      <td>1003.99</td>\n",
       "      <td>85.7</td>\n",
       "      <td>133.848</td>\n",
       "      <td>-43.848</td>\n",
       "      <td>78.092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>-0.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.91</td>\n",
       "      <td>200.9</td>\n",
       "      <td>1003.76</td>\n",
       "      <td>87.5</td>\n",
       "      <td>123.435</td>\n",
       "      <td>-33.435</td>\n",
       "      <td>89.729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ghi  dni   dhi  temp_air  wind_speed  wind_dir  \\\n",
       "Date UTC                                                               \n",
       "2019-01-01 00:00:00 -0.83  0.0 -0.83      4.39        1.87     230.1   \n",
       "2019-01-01 01:00:00 -0.93  0.0 -0.83      4.33        2.87     228.9   \n",
       "2019-01-01 02:00:00 -0.83  0.0 -0.83      4.29        2.86     229.4   \n",
       "2019-01-01 03:00:00 -0.83  0.0 -0.83      4.15        2.04     186.0   \n",
       "2019-01-01 04:00:00 -0.72  0.0 -0.83      3.85        1.91     200.9   \n",
       "\n",
       "                     pressure  humidity   zenith  elevation  azimuth  \n",
       "Date UTC                                                              \n",
       "2019-01-01 00:00:00   1004.92      86.8  157.029    -67.029   12.054  \n",
       "2019-01-01 01:00:00   1004.94      86.8  152.143    -62.143   42.533  \n",
       "2019-01-01 02:00:00   1004.68      86.7  143.742    -53.742   63.390  \n",
       "2019-01-01 03:00:00   1003.99      85.7  133.848    -43.848   78.092  \n",
       "2019-01-01 04:00:00   1003.76      87.5  123.435    -33.435   89.729  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fname = 'sample_data.hdf'\n",
    "df = pd.read_hdf(DATAPATH/fname)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def rename_cols(df: DataFrame, cols: list=['dni', 'dhi', 'zenith', 'azimuth', 'elevation']):\n",
    "    \"Rename to upper case dni and ghi cols\"\n",
    "    assert set(cols).issubset(df.columns.str.lower()), 'Missing columns on df'\n",
    "    if not set(['DNI', 'DHI']).issubset(df.columns): \n",
    "        tmy3 = (df[cols]\n",
    "                .rename(columns={'dni':'DNI', 'dhi':'DHI'}))\n",
    "        return tmy3\n",
    "    else: return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ghi', 'dni', 'dhi', 'temp_air', 'wind_speed', 'wind_dir', 'pressure',\n",
       "       'humidity', 'zenith', 'elevation', 'azimuth'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = rename_cols(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to compare to pvfactors output, so we create a function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def format_output_as_pvfactor(res: DataFrame, cuts: int): \n",
    "    \"Formats output from bifacialvf as pvfactor's one\"\n",
    "    front_cols = [f'No_{i+1}_RowFrontGTI' for i in range(cuts)]\n",
    "    back_cols = [f'No_{i+1}_RowBackGTI' for i in range(cuts)]\n",
    "    aux = pd.DataFrame(index=res.index)\n",
    "    aux['qinc_front'] = res[front_cols].mean(axis=1)\n",
    "    aux['qinc_back'] = res[back_cols].mean(axis=1)\n",
    "    aux[back_cols] = res[back_cols]\n",
    "    aux =  aux.rename(columns=dict(zip(back_cols,[f'qinc_back_{i}' for i in range(cuts-1, -1, -1)] )))\n",
    "    return aux[['qinc_front', 'qinc_back']+[f'qinc_back_{i}' for i in range(cuts)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def run_bifacialvf_simulation(data: DataFrame,  \n",
    "                          pvarray_parameters:dict={'rtr':8.,  'cellRows': 7, 'albedo':0.4}, \n",
    "                          gps_data:dict=CHAMBERY):\n",
    "    \"Run bifacialvf on data, with pvarray_parameters at location\"\n",
    "    outfile = 'output.csv'\n",
    "    pvarray_parameters.update({'sam_header':False})\n",
    "    bifacialvf.simulate_inner(rename_cols(data), gps_data, outfile, **pvarray_parameters)\n",
    "    return (pd.read_csv(outfile, header=2, index_col='date', parse_dates=True)\n",
    "            .pipe(format_output_as_pvfactor, cuts=pvarray_parameters['cellRows']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/720 [00:00<?, ?it/s]/home/tc256760/Apps/bifacialvf/bifacialvf/vf.py:300: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  projectedX2 = PcellX + np.float64(PcellY) / math.tan(startElvDown);      # Projection of ElvDown to ground in +x direction (X1 and X2 opposite nomenclature for front irradiance method)\n",
      "  2%|▏         | 17/720 [00:00<00:04, 161.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "********* \n",
      "Running Simulation for TMY3:  Chambery\n",
      "Location:   Chambery\n",
      "Lat:  45.637001  Long:  5.881  Tz  -1.0\n",
      "Parameters: beta:  0   Sazm:  180   Height:  0.5   rtr separation:  8.0   Row type:  interior   Albedo:  0.4\n",
      "Saving into output.csv\n",
      " \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 720/720 [00:03<00:00, 224.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "output = run_bifacialvf_simulation(data['June 2019'], gps_data=CHAMBERY, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'qinc_back_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8062e29d8bc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqinc_back_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5177\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5179\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'qinc_back_mean'"
     ]
    }
   ],
   "source": [
    "output.qinc_back_mean.plot(figsize=(12,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exports -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
